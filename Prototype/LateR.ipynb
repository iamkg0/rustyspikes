{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency reguation rule for spiking neural networks (Garamov K.A., Lobov S.A.)\n",
    "This notebook provides experiments from paper - LINK <br/>\n",
    "It includes visuals and a simple playground as well <br/>\n",
    "In order to obtain the exact implementation of this rule, see ```Delayed_synapse``` class at ``Prototype/synaptics.py`` - https://github.com/iamkg0/rustyspikes/blob/main/Prototype/synaptics.py <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rustyspikes import *\n",
    "res = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The essence of the rule\n",
    "Here we synchronize presynaptic spike with postsynaptic. Single synapse synchronization, just to be sure that the model works in general. <br/>\n",
    "No transmembrane dynamics just yet, timed spikes only, with <b>no influence from synapse</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp11(rt=50, aw_in=0, aw_out=6, tau=10, synaptic_limit=1, scale=1, delay=10, max_delay=100, b=0):\n",
    "    # initializes the model\n",
    "    snn = SNNModel()\n",
    "    output = Spikes_at_will(awaiting_time=aw_out, refresh_time=rt, tau=tau, synaptic_limit=synaptic_limit)\n",
    "    input = Spikes_at_will(awaiting_time=aw_in, refresh_time=rt, tau=tau, synaptic_limit=synaptic_limit)\n",
    "    synapse = Delayed_synapse(input, output, scale=scale, delay=delay, max_delay=max_delay, b=b)\n",
    "    snn.add_neuron(output)\n",
    "    snn.add_neuron(input)\n",
    "    snn.add_synapse(synapse)\n",
    "    snn.reload_graph()\n",
    "    return snn\n",
    "\n",
    "def protocol_11(model, time=100, plot=True, return_gatherer=False):\n",
    "    delay = []\n",
    "    dd = []\n",
    "    gatherer = Gatherer(model)\n",
    "    t = np.arange(int(time/res)) * res\n",
    "    for i in t:\n",
    "        model.tick()\n",
    "        if plot:\n",
    "            gatherer.gather_stats()\n",
    "        delay.append(model.syn_by_edge[1,0].delay)\n",
    "        dd.append(model.syn_by_edge[1,0].dd)\n",
    "    if plot:\n",
    "        draw_stats_gatherer(*gatherer.get_stats(pre_ids=[1], post_ids=[0]), t, fheight=12, fwidth=16, dpi=50)\n",
    "    if return_gatherer:\n",
    "        return model, delay, np.array(dd), gatherer\n",
    "    else:\n",
    "        return model, delay, np.array(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11 = exp11() # Init the model\n",
    "model_11, delay, *_ = protocol_11(model_11) # Before training\n",
    "train_time = 100000\n",
    "model_11, delay, *_ = protocol_11(model_11, time=train_time, plot=False, return_gatherer=False) # Training procedure\n",
    "f = plt.figure() # This figure will plot delay changes during training\n",
    "plt.xlabel('time, ms')\n",
    "plt.ylabel('delay, ms')\n",
    "f.set_dpi(50)\n",
    "plt.plot(np.arange(int(train_time / res)) * res, delay)\n",
    "plt.show()\n",
    "model_11, delay, *_ = protocol_11(model_11) # Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>b value</b>\n",
    "Now, let us see that depolarization bias <b><i>b</i></b> is robust. Let's see how it works with Izhikevich neuron. We've got just one presynaptic input, so that means the goal is to find <i>b</i> that keeps delay steady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp12(sc=7, rt=100, aw=1, tau=10, synaptic_limit=1, delay=20, max_delay=100, d_lr=1, b=6.7):\n",
    "    # OPTIMAL PARAMS FOR 0 IMPACT:\n",
    "    # rt0 = 100 msec, aw = 1 msec, tau = 10, delay = 0 (any, in fact), b = 6.7\n",
    "    snn = SNNModel()\n",
    "    output = Izhikevich(tau=tau, synaptic_limit=synaptic_limit)\n",
    "    input = Spikes_at_will(awaiting_time=aw, refresh_time=rt, synaptic_limit=synaptic_limit, tau=tau)\n",
    "    syn = Delayed_synapse(input, output, scale=sc, delay=delay, max_delay=max_delay, d_lr=d_lr, b=b)\n",
    "    snn.add_neuron(output)\n",
    "    snn.add_neuron(input)\n",
    "    snn.add_synapse(syn)\n",
    "    snn.reload_graph()\n",
    "    return snn\n",
    "\n",
    "def protocol_12(model, time=100, plot=True, return_gatherer=False):\n",
    "    delay = []\n",
    "    dd = []\n",
    "    gatherer = Gatherer(model)\n",
    "    t = np.arange(int(time/res)) * res\n",
    "    for i in t:\n",
    "        model.tick()\n",
    "        if plot:\n",
    "            gatherer.gather_stats()\n",
    "        delay.append(model.syn_by_edge[1,0].delay)\n",
    "        dd.append(model.syn_by_edge[1,0].dd)\n",
    "    if plot:\n",
    "        draw_stats_gatherer(*gatherer.get_stats(pre_ids=[1], post_ids=[0]), t, fheight=12, fwidth=16, dpi=50)\n",
    "    if return_gatherer:\n",
    "        return model, delay, np.array(dd), gatherer\n",
    "    else:\n",
    "        return model, delay, np.array(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_12 = exp12()\n",
    "model_12, delay, *_ = protocol_12(model_12) # Before training\n",
    "train_time = 100000\n",
    "model_12, delay, *_ = protocol_12(model_12, time=train_time, plot=False, return_gatherer=False) # Training procedure\n",
    "f = plt.figure() # This figure will plot delay changes during training\n",
    "plt.xlabel('time, ms')\n",
    "plt.ylabel('delay, ms')\n",
    "f.set_dpi(50)\n",
    "plt.plot(np.arange(int(train_time / res)) * res, delay)\n",
    "plt.show()\n",
    "model_12, delay, *_ = protocol_12(model_12) # Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's prove our model works with multidimensional neuron!\n",
    "We build simple dynamic pattern and feed it to Izhikevich neuron, so it can learn it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp21(sc=7, num_inputs=10, tau=10, synaptic_limit=1, delay=1, max_delay=100, d_lr=.1, b=4.6):\n",
    "    snn = SNNModel()\n",
    "    output = Izhikevich(tau=tau, synaptic_limit=synaptic_limit)\n",
    "    snn.add_neuron(output)\n",
    "    for saw in range(num_inputs):\n",
    "        neu = Spikes_at_will(tau=tau, synaptic_limit=synaptic_limit)\n",
    "        snn.add_neuron(neu)\n",
    "        syn = Delayed_synapse(neu, output, scale=sc, delay=delay, max_delay=max_delay, d_lr=d_lr, b=b)\n",
    "        snn.add_synapse(syn)\n",
    "    snn.reload_graph()\n",
    "    return snn\n",
    "\n",
    "def run_protocol(model, sampler, sample_time=150, interval=6, runs=3, lr=.1, d_lr=None, test=False,\n",
    "                 freeze_delays=False, gather_data=False, plot=False, plast_type=None, return_gatherer=False, gather_delays=True,\n",
    "                 logger=None, init_weights=None, stick_del_w_to_one=True):\n",
    "    learning_rule = plast_type\n",
    "    if not test:\n",
    "        model.set_rule_to_all(plast_type)\n",
    "        model.set_lr_to_all(lr)\n",
    "        if d_lr:\n",
    "            model.set_d_lr(d_lr)\n",
    "    else:\n",
    "        model.set_rule_to_all(None)\n",
    "        model.set_lr_to_all(0)\n",
    "        if d_lr:\n",
    "            model.set_d_lr(0)\n",
    "    delay = [[] for i in range(len(model.show_config()['Neurons'])-1)]\n",
    "    dd = [[] for i in range(len(model.show_config()['Neurons'])-1)]\n",
    "    num_spikes = [0 for i in range(len(sampler))]\n",
    "\n",
    "    if gather_data:\n",
    "        gatherer = Gatherer(model)\n",
    "\n",
    "    if test:\n",
    "        length = len(sampler)\n",
    "    else:\n",
    "        length = 1\n",
    "\n",
    "    for p in range(length):\n",
    "        sample = sampler[p]\n",
    "        for run in range(runs):\n",
    "            aw = 1\n",
    "            for neu in sample:\n",
    "                model.neurons[neu].awaiting_time = aw\n",
    "                model.neurons[neu].refresh()\n",
    "                aw += interval\n",
    "            for t in np.arange(int(sample_time/res)) * res:\n",
    "                model.tick(freeze_delays=freeze_delays)\n",
    "                if model.neurons[0].get_spike_status():\n",
    "                    num_spikes[p] += 1\n",
    "                if gather_data:\n",
    "                    gatherer.gather_stats()\n",
    "                if not freeze_delays:\n",
    "                    if gather_delays:\n",
    "                        for edge in range(1, len(model.show_config()['Neurons'])):\n",
    "                            #print(np.array(delay).shape, np.array(dd).shape)\n",
    "                            delay[edge-1].append(model.syn_by_edge[edge,0].delay)\n",
    "                            dd[edge-1].append(model.syn_by_edge[edge,0].dd)\n",
    "    if plot and gather_data:\n",
    "        draw_stats_gatherer(*gatherer.get_stats(pre_ids=list(range(1, len(model.show_config()['Neurons']))),\n",
    "                                                post_ids=[0]), time_range=sample_time*runs*(length), resolution=res)\n",
    "    \n",
    "    if logger:\n",
    "        # values to write:\n",
    "        input_size = len(model.get_presyn_neurons_ids(*model.get_output_ids()))\n",
    "        aw_time = interval\n",
    "        #sample_time\n",
    "        #lr\n",
    "        #runs\n",
    "        #d_lr\n",
    "        scale = model.get_first_synapse().scale\n",
    "        rt = model.neurons[1].refresh_time\n",
    "        num_patterns = len(sampler)\n",
    "        synaptic_limit = model.neurons[1].synaptic_limit\n",
    "        slow_var_limit = model.get_first_synapse().slow_variable_limit\n",
    "        slow_tau = model.get_first_synapse().slow_tau\n",
    "        forget_tau = model.get_first_synapse().forget_tau\n",
    "        spikes = num_spikes\n",
    "        noise = model.get_output_neurons()[0].noise\n",
    "        if type(model.get_first_synapse()) == Delayed_synapse:\n",
    "            b = model.get_first_synapse().b\n",
    "            max_delay = model.get_first_synapse().max_delay\n",
    "        else:\n",
    "            b = None\n",
    "            max_delay = None\n",
    "\n",
    "        if stick_del_w_to_one and learning_rule == 'delayed':\n",
    "            init_weights = 1\n",
    "\n",
    "        sample_pack = [input_size, aw_time, sample_time, lr, runs, d_lr, scale, rt,\n",
    "                            num_patterns, synaptic_limit, slow_var_limit, slow_tau, forget_tau,\n",
    "                            spikes, b, max_delay, learning_rule, noise, init_weights]\n",
    "        for i in range(len(sample_pack)):\n",
    "            if sample_pack[i] == None:\n",
    "                sample_pack[i] = '-'\n",
    "        logger.write_sample(sample_pack)\n",
    "\n",
    "    if return_gatherer and gather_data:\n",
    "        return model, np.array(delay).T, np.array(dd), np.array(num_spikes), gatherer\n",
    "    else:\n",
    "        return model, np.array(delay).T, np.array(dd), np.array(num_spikes)\n",
    "    \n",
    "def cfg_slicer(cfg):\n",
    "    '''\n",
    "    No, im not ashamed\n",
    "    '''\n",
    "    configs = []\n",
    "    for input_size in cfg['input_size']:\n",
    "        for aw_time in cfg['aw_time']:\n",
    "            for sample_time in cfg['sample_time']:\n",
    "                for lr in cfg['lr']:\n",
    "                    for runs in cfg['runs']:\n",
    "                        for d_lr in cfg['d_lr']:\n",
    "                            for scale in cfg['scale']:\n",
    "                                for rt in cfg['rt']:\n",
    "                                    for num_patterns in cfg['num_rand_patterns']:\n",
    "                                        for synaptic_limit in cfg['synaptic_limit']:\n",
    "                                            for slow_tau in cfg['slow_tau']:\n",
    "                                                for forget_tau in cfg['forget_tau']:\n",
    "                                                    for b in cfg['b']:\n",
    "                                                        for max_delay in cfg['max_delay']:\n",
    "                                                            for learning_rule in cfg['learning_rule']:\n",
    "                                                                for noise in cfg['noise']:\n",
    "                                                                    for weights in cfg['weights']:\n",
    "                                                                        configs.append(\n",
    "                                                                            {\n",
    "                                                                                'input_size': input_size,\n",
    "                                                                                'aw_time': aw_time,\n",
    "                                                                                'sample_time': sample_time,\n",
    "                                                                                'lr': lr,\n",
    "                                                                                'runs': runs,\n",
    "                                                                                'd_lr': d_lr,\n",
    "                                                                                'scale': scale,\n",
    "                                                                                'rt': rt,\n",
    "                                                                                'num_patterns': num_patterns,\n",
    "                                                                                'synaptic_limit': synaptic_limit,\n",
    "                                                                                'slow_tau': slow_tau,\n",
    "                                                                                'forget_tau': forget_tau,\n",
    "                                                                                'b': b,\n",
    "                                                                                'max_delay': max_delay,\n",
    "                                                                                'learning_rule': learning_rule,\n",
    "                                                                                'noise': noise,\n",
    "                                                                                'weights': weights\n",
    "                                                                            }\n",
    "                                                                        )\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) #for reproducibility\n",
    "log_path = r'C:\\Users\\User\\Desktop'\n",
    "log_name = 'output.csv'\n",
    "log = LogHandler(path=log_path, filename=log_name)\n",
    "\n",
    "# PROTOCOL CONFIGURATION\n",
    "\n",
    "config = {\n",
    "    'input_size': [5],\n",
    "    'aw_time': [5],\n",
    "    'sample_time': [150],\n",
    "    'lr': [.01],\n",
    "    'runs': [250],\n",
    "    'd_lr': [10],\n",
    "    'scale': [0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3],\n",
    "    'rt': [250],\n",
    "    'num_rand_patterns': [5],\n",
    "    'synaptic_limit': [1],\n",
    "    'slow_tau': [100],\n",
    "    'forget_tau': [100],\n",
    "    'b': [7],\n",
    "    'max_delay': [100],\n",
    "    'learning_rule': ['pair_stdp', 't_stdp', 'delayed'],\n",
    "    'noise': [0.5, 0.7, 1, 1.3],\n",
    "    'weights': [(1, 1)],\n",
    "}\n",
    "del_w_to_one = True\n",
    "\n",
    "num_tries = 1\n",
    "for i in config:\n",
    "    num_tries *= len(config[i])\n",
    "\n",
    "patterns, num_inputs, num_patterns = sampler(num_inputs=config['input_size'][0], num_rand_patterns=config['num_rand_patterns'][0])\n",
    "log.create()\n",
    "log.define_cols(('input_size', 'aw_time', 'sample_time', 'lr', 'runs', 'd_lr', 'scale', 'rt',\n",
    "                            'num_patterns', 'synaptic_limit', 'slow_var_limit', 'slow_tau', 'forget_tau',\n",
    "                            'spikes (0 is gt)', 'b', 'max_delay', 'learning_rule', 'noise', 'init_weights'))\n",
    "log.comment([*patterns.values()])\n",
    "print(f'patterns are: {patterns}')\n",
    "\n",
    "attempt_num = 0\n",
    "cfgs = cfg_slicer(config)\n",
    "for cfg in cfgs:\n",
    "\n",
    "    attempt_num += 1\n",
    "    print('\\n Calculation in progress...')\n",
    "    print(f'Run {attempt_num}/{num_tries}')\n",
    "\n",
    "    if cfg['learning_rule'] == 'delayed':\n",
    "        delayed = True\n",
    "    else:\n",
    "        delayed = False\n",
    "    model = one_neu_dynamics(num_input=cfg['input_size'], scale=cfg['scale'], rt=cfg['rt']  , interval=cfg['aw_time'],\n",
    "                            learning_rule=cfg['learning_rule'], delayed=delayed,\n",
    "                            lr=cfg['lr'], tau=30, d_lr=.1, synaptic_limit=cfg['synaptic_limit'],\n",
    "                            slow_variable_limit=cfg['synaptic_limit'], max_delay=cfg['max_delay'], b=cfg['b'],\n",
    "                            slow_tau=cfg['slow_tau'], forget_tau=cfg['forget_tau'], delay=0,\n",
    "                            noise=cfg['noise'], weights=cfg['weights'], stick_del_w_to_one=del_w_to_one)\n",
    "    \n",
    "    # TRAIN\n",
    "    model, *_ = run_protocol(model, sampler=patterns, sample_time=cfg['sample_time'], interval=cfg['aw_time'],\n",
    "                    runs=cfg['runs'], lr=cfg['lr'], d_lr=cfg['d_lr'], test=False,\n",
    "                    freeze_delays=False, gather_data=False, plot=False, plast_type=cfg['learning_rule'],\n",
    "                    return_gatherer=False, gather_delays=False, logger=None, init_weights=cfg['weights'],\n",
    "                    stick_del_w_to_one=del_w_to_one)\n",
    "\n",
    "    # TEST\n",
    "    model, *_ = run_protocol(model, sampler=patterns, sample_time=cfg['sample_time'], interval=cfg['aw_time'],\n",
    "                    runs=cfg['runs'], lr=cfg['lr'], d_lr=cfg['d_lr'], test=True,\n",
    "                    freeze_delays=False, gather_data=False, plot=False, plast_type=cfg['learning_rule'],\n",
    "                    return_gatherer=False, gather_delays=False, logger=log, init_weights=cfg['weights'],\n",
    "                    stick_del_w_to_one=del_w_to_one)\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\User\\Desktop\\output.csv', comment='#', delimiter='\\t')\n",
    "runs = df['runs'][0]\n",
    "df['spikes (0 is gt)'] = df['spikes (0 is gt)'].apply(lambda x: np.array(eval(x)), 0)\n",
    "sps = np.stack(df['spikes (0 is gt)'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_known = sps[:,0]\n",
    "freq_unknown = np.sum(sps[:,1:], axis=1) / 4\n",
    "Q = np.divide(2*freq_known, (freq_known + freq_unknown)) - 1\n",
    "freq_unknown.shape\n",
    "\n",
    "ai = np.where(Q>.3)[0]\n",
    "a = sps[ai]\n",
    "bi = np.where(np.max(a[:, 1:], axis=1) < a[:,0]-100)[0]\n",
    "b = a[bi]\n",
    "ci = np.where(np.sum(b, axis=1) > 100)[0]\n",
    "filtered = df.loc[[*ai[bi[ci]].tolist()]]\n",
    "filtered[['runs', 'num_patterns', 'spikes (0 is gt)', 'learning_rule']]\n",
    "delayed_idxs = df.index[df['learning_rule'] == 'delayed'].tolist()\n",
    "pair_idxs = df.index[df['learning_rule'] == 'pair_stdp'].tolist()\n",
    "t_idxs = df.index[df['learning_rule'] == 't_stdp'].tolist()\n",
    "strdp_idxs = df.index[df['learning_rule'] == 'strdp'].tolist()\n",
    "delayed_n = np.sum(sps[delayed_idxs], axis=1)\n",
    "pair_n = np.sum(sps[pair_idxs], axis=1)\n",
    "t_n = np.sum(sps[t_idxs], axis=1)\n",
    "strdp_n = np.sum(sps[strdp_idxs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsize = 2\n",
    "all_n = sps[:,0] / runs\n",
    "plt.figure(dpi=300)\n",
    "plt.grid(visible=True, which='major', linestyle=':')\n",
    "plt.scatter(all_n[delayed_idxs], Q[delayed_idxs], s=pointsize, label='delayed')\n",
    "plt.scatter(all_n[pair_idxs], Q[pair_idxs], s=pointsize, label='pair stdp')\n",
    "plt.scatter(all_n[t_n], Q[t_n], s=pointsize, label='tstdp')\n",
    "plt.scatter(all_n[strdp_n], Q[strdp_n], s=pointsize, label='strdp')\n",
    "plt.ylim((-1, 1))\n",
    "plt.xlim((0, 2))\n",
    "plt.xlabel('P')\n",
    "plt.ylabel('Q')\n",
    "plt.legend(markerscale=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsize = 20\n",
    "all_n = sps[:,0] / runs\n",
    "plt.figure(dpi=300)\n",
    "plt.grid(visible=True, which='major', linestyle=':')\n",
    "plt.scatter(all_n[delayed_idxs], Q[delayed_idxs], s=pointsize, label='delayed')\n",
    "plt.scatter(all_n[pair_idxs], Q[pair_idxs], s=pointsize, label='pair stdp')\n",
    "plt.scatter(all_n[t_n], Q[t_n], s=pointsize, label='tstdp')\n",
    "plt.scatter(all_n[strdp_n], Q[strdp_n], s=pointsize, label='strdp')\n",
    "plt.ylim((0.0, .45))\n",
    "plt.xlim((0.85, 1.15))\n",
    "plt.xlabel('P')\n",
    "plt.ylabel('Q')\n",
    "plt.legend(markerscale=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = delayed_3_to_1(out_type='IZH')\n",
    "demo.set_scale(1.4)\n",
    "demo.syn_by_edge[0, 3].delay = 40\n",
    "demo.syn_by_edge[1, 3].delay = 120\n",
    "demo.syn_by_edge[2, 3].delay = 200\n",
    "gath = Gatherer(demo)\n",
    "for i in range(2000):\n",
    "    demo.tick()\n",
    "    gath.gather_stats()\n",
    "draw_stats_gatherer(*gath.get_stats(), time_range=np.arange(200*10)*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo1 = delayed_3_to_1(out_type='IZH')\n",
    "demo1.set_scale(1.4)\n",
    "demo1.syn_by_edge[0, 3].delay = 100\n",
    "demo1.syn_by_edge[1, 3].delay = 60\n",
    "demo1.syn_by_edge[2, 3].delay = 20\n",
    "print(demo1.syn_by_edge[1, 3].delay)\n",
    "gath1 = Gatherer(demo1)\n",
    "for i in range(2000):\n",
    "    demo1.tick()\n",
    "    gath1.gather_stats()\n",
    "draw_stats_gatherer(*gath1.get_stats(), time_range=np.arange(200*10)*.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how delays are affected by <i>b</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protocol_b(model, interval=10, train_time=100, lr=1, rt=150, noise=0):\n",
    "    for i in range(len(model.syn_by_edge)):\n",
    "        model[i+1].awaiting_time = i * interval\n",
    "        model[i+1].refresh_time = rt\n",
    "    model[0].noise = noise\n",
    "    model.set_lr_to_all(lr)\n",
    "    t = np.arange(int(train_time/res)) * res\n",
    "    # deltas = [[] for i in range(len(model.syn_by_edge))]\n",
    "    for i in t:\n",
    "        model.tick()\n",
    "        # for i in range(len(model.syn_by_edge.values())):\n",
    "        #     deltas[i].append(model.syn_by_edge[i+1, 0].delay)\n",
    "    delays = []\n",
    "    for i in model.syn_by_edge.values():\n",
    "        delays.append(i.delay)\n",
    "    # plt.plot(np.array(deltas).T)\n",
    "    # plt.show()\n",
    "    return np.array(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=.1\n",
    "num_inputs = 8\n",
    "interval = 6\n",
    "scale = 2.5\n",
    "noise = .5\n",
    "train_time = 1000000\n",
    "rt = 150\n",
    "lr = 1\n",
    "max_del = 100\n",
    "b_less_dep = exp21(sc=scale, num_inputs=num_inputs, tau=10, synaptic_limit=1, delay=10, max_delay=max_del, d_lr=lr, b=4.5)\n",
    "b_close_dep = exp21(sc=scale, num_inputs=num_inputs, tau=10, synaptic_limit=1, delay=10, max_delay=max_del, d_lr=lr, b=6.)\n",
    "b_greater_dep = exp21(sc=scale, num_inputs=num_inputs, tau=10, synaptic_limit=1, delay=10, max_delay=max_del, d_lr=lr, b=7.5)\n",
    "delays_less = protocol_b(b_less_dep, interval=interval, train_time=train_time, lr=lr, rt=rt, noise=noise)\n",
    "delays_close = protocol_b(b_close_dep, interval=interval, train_time=train_time, lr=lr, rt=rt, noise=noise)\n",
    "delays_greater = protocol_b(b_greater_dep, interval=interval, train_time=train_time, lr=lr, rt=rt, noise=noise)\n",
    "plt.figure()\n",
    "plt.scatter(list(range(1,num_inputs+1)),delays_less*res, label='b<dep')\n",
    "plt.scatter(list(range(1,num_inputs+1)),delays_close*res, label='b~dep')\n",
    "plt.scatter(list(range(1,num_inputs+1)),delays_greater*res, label='b>dep')\n",
    "plt.legend(markerscale=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(10)\n",
    "fig.set_dpi(300)\n",
    "plt.xlabel('Order of presynaptic neurons')\n",
    "plt.ylabel('Delay, ms')\n",
    "plt.grid(visible=True, alpha=.3)\n",
    "plt.plot(list(range(1,num_inputs+1)),delays_less*res, '-.', alpha=.5)\n",
    "plt.plot(list(range(1,num_inputs+1)),delays_close*res, '-.', alpha=.5)\n",
    "plt.plot(list(range(1,num_inputs+1)),delays_greater*res, '-.', alpha=.5)\n",
    "plt.plot(list(range(1, num_inputs+1)), [i*interval for i in range(num_inputs-1, -1, -1)], '-.', alpha=.5, c='black')\n",
    "plt.scatter(list(range(1, num_inputs+1)), [i*interval for i in range(num_inputs-1, -1, -1)], label='Perfect synchronization', s=100, c='black')\n",
    "plt.scatter(list(range(1,num_inputs+1)),delays_less*res, label='b < SThDT', s=100)\n",
    "plt.scatter(list(range(1,num_inputs+1)),delays_close*res, label='b â‰ˆ SThDT', s=100)\n",
    "plt.scatter(list(range(1,num_inputs+1)),delays_greater*res, label='b > SThDT', s=100)\n",
    "plt.legend(markerscale=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
